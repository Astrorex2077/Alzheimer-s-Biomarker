{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af16c79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset Generation for Tau Protein Misfolding Prediction\n",
    "\n",
    "This notebook:\n",
    "1. Loads tau protein sequences from FASTA file\n",
    "2. Creates or loads labels\n",
    "3. Validates data quality\n",
    "4. Saves processed datasets\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import ONLY dataset-related utilities\n",
    "from utils.dataset import (\n",
    "    load_fasta,\n",
    "    save_fasta,\n",
    ")\n",
    "\n",
    "from utils.dataset import (\n",
    "    create_synthetic_labels,\n",
    "    load_labels,\n",
    "    validate_sequences,\n",
    "    save_core_tables,\n",
    ")\n",
    "\n",
    "from utils.config import (\n",
    "    FASTA_FILE,\n",
    "    SEQUENCES_CSV,\n",
    "    LABELS_CSV,\n",
    "    PROCESSED_DATA_DIR,\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1489648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 06:19:28,146 - utils.dataset - INFO - Loading FASTA file: /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/data/raw/tau_all_species.fasta\n",
      "2025-12-18 06:19:28,148 - utils.dataset - ERROR - Error loading FASTA file: No sequences found in /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/data/raw/tau_all_species.fasta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: LOADING FASTA FILE\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No sequences found in /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/data/raw/tau_all_species.fasta",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Created example FASTA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFASTA_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Load FASTA\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m df_sequences = \u001b[43mload_fasta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFASTA_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_sequences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sequences\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_sequences.columns.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Alzheimer-s-Biomarker/tau_stacking_project/notebooks/../utils/dataset.py:105\u001b[39m, in \u001b[36mload_fasta\u001b[39m\u001b[34m(fasta_path)\u001b[39m\n\u001b[32m     96\u001b[39m     sequences.append({\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mprotein_id\u001b[39m\u001b[33m'\u001b[39m: protein_id,\n\u001b[32m     98\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m: description,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mspecies\u001b[39m\u001b[33m'\u001b[39m: species,\n\u001b[32m    102\u001b[39m     })\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sequences:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo sequences found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfasta_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m df = pd.DataFrame(sequences)\n\u001b[32m    108\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sequences from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df[\u001b[33m'\u001b[39m\u001b[33mspecies\u001b[39m\u001b[33m'\u001b[39m].unique())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m species\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: No sequences found in /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/data/raw/tau_all_species.fasta"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load tau protein sequences from FASTA file\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: LOADING FASTA FILE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if FASTA file exists\n",
    "if not FASTA_FILE.exists():\n",
    "    print(f\"‚ö†Ô∏è  FASTA file not found: {FASTA_FILE}\")\n",
    "    print(\"Creating example FASTA file for demonstration...\")\n",
    "    \n",
    "    # Create example sequences (replace with real data)\n",
    "    example_sequences = pd.DataFrame({\n",
    "        'protein_id': [f'TAU_{i:04d}' for i in range(100)],\n",
    "        'description': ['Tau protein example'] * 100,\n",
    "        'sequence': ['MAEPRQEFEVMEDHAGTYGLGDRKDQGGYTMHQDQEGDTDAGLKESPLQTP'] * 100,\n",
    "        'length': [52] * 100,\n",
    "        'species': ['Homo sapiens'] * 50 + ['Mus musculus'] * 50,\n",
    "    })\n",
    "    \n",
    "    # Save example FASTA\n",
    "    FASTA_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    save_fasta(example_sequences, FASTA_FILE)\n",
    "    print(f\"‚úÖ Created example FASTA: {FASTA_FILE}\")\n",
    "\n",
    "# Load FASTA\n",
    "df_sequences = load_fasta(FASTA_FILE)\n",
    "\n",
    "print(f\"\\nüìä Loaded {len(df_sequences)} sequences\")\n",
    "print(f\"Columns: {df_sequences.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explore the loaded sequences\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 2: DATA EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display first few sequences\n",
    "print(\"\\nüìã First 5 sequences:\")\n",
    "print(df_sequences.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nüìä Sequence length statistics:\")\n",
    "print(df_sequences['length'].describe())\n",
    "\n",
    "# Species distribution\n",
    "print(\"\\nüåç Species distribution:\")\n",
    "print(df_sequences['species'].value_counts())\n",
    "\n",
    "# Visualize sequence length distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_sequences['length'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Sequence Length')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Sequence Lengths')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df_sequences['length'])\n",
    "axes[1].set_ylabel('Sequence Length')\n",
    "axes[1].set_title('Sequence Length Box Plot')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Sequence length range: {df_sequences['length'].min()} - {df_sequences['length'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Validate protein sequences for quality\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 3: SEQUENCE VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Validate sequences\n",
    "is_valid, errors = validate_sequences(df_sequences, sequence_column='sequence')\n",
    "\n",
    "if is_valid:\n",
    "    print(\"‚úÖ All sequences are valid!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Found {len(errors)} validation errors:\")\n",
    "    for i, error in enumerate(errors[:10]):  # Show first 10 errors\n",
    "        print(f\"  {i+1}. {error}\")\n",
    "    \n",
    "    if len(errors) > 10:\n",
    "        print(f\"  ... and {len(errors) - 10} more errors\")\n",
    "\n",
    "# Check amino acid composition\n",
    "print(\"\\nüî¨ Checking amino acid composition...\")\n",
    "all_amino_acids = ''.join(df_sequences['sequence'].tolist())\n",
    "unique_chars = set(all_amino_acids)\n",
    "valid_aa = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "\n",
    "print(f\"Unique characters found: {sorted(unique_chars)}\")\n",
    "invalid_chars = unique_chars - valid_aa\n",
    "if invalid_chars:\n",
    "    print(f\"‚ö†Ô∏è  Invalid characters: {invalid_chars}\")\n",
    "else:\n",
    "    print(\"‚úÖ All characters are valid amino acids\")\n",
    "\n",
    "# Calculate amino acid frequency\n",
    "aa_counts = {aa: all_amino_acids.count(aa) for aa in valid_aa}\n",
    "total_aa = sum(aa_counts.values())\n",
    "aa_freq = {aa: count/total_aa*100 for aa, count in aa_counts.items()}\n",
    "\n",
    "# Plot amino acid frequency\n",
    "plt.figure(figsize=(14, 5))\n",
    "sorted_aa = sorted(aa_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "aas, freqs = zip(*sorted_aa)\n",
    "\n",
    "plt.bar(aas, freqs, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Amino Acid')\n",
    "plt.ylabel('Frequency (%)')\n",
    "plt.title('Amino Acid Composition Across All Sequences')\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2833d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create or load labels for sequences\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 4: LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if labels file exists\n",
    "if LABELS_CSV.exists():\n",
    "    print(f\"Loading existing labels from: {LABELS_CSV}\")\n",
    "    df_labels = load_labels(LABELS_CSV)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Labels file not found. Creating synthetic labels for demonstration...\")\n",
    "    print(\"‚ùó IMPORTANT: Replace with real labels for actual research!\")\n",
    "    \n",
    "    # Create synthetic labels\n",
    "    df_labels = create_synthetic_labels(df_sequences, positive_ratio=0.3)\n",
    "    \n",
    "    # Save synthetic labels\n",
    "    LABELS_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_labels.to_csv(LABELS_CSV, index=False)\n",
    "    print(f\"‚úÖ Saved synthetic labels to: {LABELS_CSV}\")\n",
    "\n",
    "# Display label statistics\n",
    "print(f\"\\nüìä Label statistics:\")\n",
    "print(df_labels.head())\n",
    "print(f\"\\nTotal labels: {len(df_labels)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_labels['label'].value_counts())\n",
    "print(f\"\\nLabel proportions:\")\n",
    "print(df_labels['label'].value_counts(normalize=True))\n",
    "\n",
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count plot\n",
    "label_counts = df_labels['label'].value_counts()\n",
    "axes[0].bar(['Normal (0)', 'Misfolding (1)'], \n",
    "            [label_counts[0], label_counts[1]], \n",
    "            color=['lightgreen', 'salmon'],\n",
    "            edgecolor='black')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Label Distribution (Counts)')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie([label_counts[0], label_counts[1]], \n",
    "            labels=['Normal (0)', 'Misfolding (1)'],\n",
    "            colors=['lightgreen', 'salmon'],\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90)\n",
    "axes[1].set_title('Label Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb68e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge sequences with labels\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 5: MERGE SEQUENCES AND LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Merge dataframes\n",
    "df_merged = df_sequences.merge(df_labels, on='protein_id', how='inner')\n",
    "\n",
    "print(f\"üìä Merged dataset:\")\n",
    "print(f\"  Total samples: {len(df_merged)}\")\n",
    "print(f\"  Features: {df_merged.columns.tolist()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nüîç Missing values:\")\n",
    "print(df_merged.isnull().sum())\n",
    "\n",
    "# Display merged data\n",
    "print(f\"\\nüìã First 5 rows of merged data:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# Analyze sequence length by label\n",
    "print(f\"\\nüìè Sequence length by label:\")\n",
    "print(df_merged.groupby('label')['length'].describe())\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df_merged.boxplot(column='length', by='label', ax=ax)\n",
    "ax.set_xlabel('Label (0=Normal, 1=Misfolding)')\n",
    "ax.set_ylabel('Sequence Length')\n",
    "ax.set_title('Sequence Length Distribution by Label')\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save processed sequences and labels\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 6: SAVE PROCESSED DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prepare data for saving\n",
    "df_sequences_final = df_merged[['protein_id', 'description', 'sequence', 'length', 'species']]\n",
    "df_labels_final = df_merged[['protein_id', 'label', 'source']]\n",
    "\n",
    "# Create dummy splits table (will be properly split in next notebook)\n",
    "df_splits_temp = pd.DataFrame({\n",
    "    'protein_id': df_merged['protein_id'],\n",
    "    'split': 'none'  # Placeholder\n",
    "})\n",
    "\n",
    "# Save\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_sequences_final.to_csv(SEQUENCES_CSV, index=False)\n",
    "df_labels_final.to_csv(LABELS_CSV, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved sequences to: {SEQUENCES_CSV}\")\n",
    "print(f\"‚úÖ Saved labels to: {LABELS_CSV}\")\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"  Total sequences: {len(df_sequences_final)}\")\n",
    "print(f\"  Total labels: {len(df_labels_final)}\")\n",
    "print(f\"  Sequence length: {df_sequences_final['length'].min()} - {df_sequences_final['length'].max()}\")\n",
    "print(f\"  Label 0 (Normal): {(df_labels_final['label']==0).sum()}\")\n",
    "print(f\"  Label 1 (Misfolding): {(df_labels_final['label']==1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary and next steps\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ DATASET GENERATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìã Generated Files:\")\n",
    "print(f\"  1. {SEQUENCES_CSV}\")\n",
    "print(f\"  2. {LABELS_CSV}\")\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(df_merged)}\")\n",
    "print(f\"  Features: {len(df_merged.columns)}\")\n",
    "print(f\"  Avg sequence length: {df_merged['length'].mean():.1f}\")\n",
    "print(f\"  Class balance: {(df_merged['label']==1).mean()*100:.1f}% positive\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"  ‚Üí Run notebook 02_preprocessing.ipynb to:\")\n",
    "print(\"     - Create train/val/test splits\")\n",
    "print(\"     - Generate embeddings\")\n",
    "print(\"     - Encode sequences\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fef95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
