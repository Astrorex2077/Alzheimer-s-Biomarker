{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a006fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n",
      "Device: cpu\n",
      "Working directory: /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/notebooks\n",
      "\n",
      "üîÅ Harmonizing variable names (aliases)...\n",
      "‚úÖ Harmonization complete. Use `train_encoded`/`y_train` and `train_embeddings` where appropriate.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model Training for Tau Protein Misfolding Prediction\n",
    "\n",
    "This notebook:\n",
    "1. Trains Model A (ProtBERT Frozen + SVM)\n",
    "2. Trains Model B (ProtBERT Fine-tuned)\n",
    "3. Trains Model C (CNN-BiLSTM)\n",
    "4. Trains Model D (Lite Transformer)\n",
    "5. Generates predictions for stacking\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Import our models and utilities\n",
    "from models import (\n",
    "    ProtBERTFrozenSVM,\n",
    "    ProtBERTFineTuneClassifier,\n",
    "    CNNBiLSTMClassifier,\n",
    "    LiteTransformerClassifier\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    train_torch_model,\n",
    "    train_sklearn_model,\n",
    "    predict_with_torch_model,\n",
    "    predict_with_sklearn_model,\n",
    "    compute_classification_metrics,\n",
    "    EMBEDDINGS_DIR,\n",
    "    SAVED_MODELS_DIR,\n",
    "    PREDICTIONS_DIR,\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Create directories\n",
    "SAVED_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Harmonize variable names and provide fallbacks for legacy cell names/files\n",
    "# This ensures different notebook cells can reference consistent names\n",
    "print(\"\\nüîÅ Harmonizing variable names (aliases)...\")\n",
    "# Alias legacy in-memory names if present\n",
    "if 'train_enc' in globals():\n",
    "    train_encoded = globals()['train_enc']\n",
    "if 'val_enc' in globals():\n",
    "    val_encoded = globals()['val_enc']\n",
    "if 'test_enc' in globals():\n",
    "    test_encoded = globals()['test_enc']\n",
    "if 'train_labels' in globals():\n",
    "    y_train = globals()['train_labels']\n",
    "if 'val_labels' in globals():\n",
    "    y_val = globals()['val_labels']\n",
    "if 'test_labels' in globals():\n",
    "    y_test = globals()['test_labels']\n",
    "\n",
    "# Load ProtBERT embeddings on demand if present\n",
    "if 'train_embeddings' not in globals() and (EMBEDDINGS_DIR / 'protbert_train.npy').exists():\n",
    "    train_embeddings = np.load(EMBEDDINGS_DIR / 'protbert_train.npy')\n",
    "if 'val_embeddings' not in globals() and (EMBEDDINGS_DIR / 'protbert_val.npy').exists():\n",
    "    val_embeddings = np.load(EMBEDDINGS_DIR / 'protbert_val.npy')\n",
    "if 'test_embeddings' not in globals() and (EMBEDDINGS_DIR / 'protbert_test.npy').exists():\n",
    "    test_embeddings = np.load(EMBEDDINGS_DIR / 'protbert_test.npy')\n",
    "print(\"‚úÖ Harmonization complete. Use `train_encoded`/`y_train` and `train_embeddings` where appropriate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0768753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING PREPROCESSED DATA\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "  Train: (141, 1146)\n",
      "  Val:   (31, 1146)\n",
      "  Test:  (31, 1146)\n",
      "  Sequence length: 1146\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define absolute paths\n",
    "PROJECT_ROOT = Path('/workspaces/Alzheimer-s-Biomarker/tau_stacking_project')\n",
    "EMBEDDINGS_DIR = PROJECT_ROOT / 'results' / 'embeddings'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load encoded sequences\n",
    "train_enc = np.load(EMBEDDINGS_DIR / 'encoded_train.npy')\n",
    "val_enc = np.load(EMBEDDINGS_DIR / 'encoded_val.npy')\n",
    "test_enc = np.load(EMBEDDINGS_DIR / 'encoded_test.npy')\n",
    "\n",
    "# Load attention masks\n",
    "train_mask = np.load(EMBEDDINGS_DIR / 'masks_train.npy')\n",
    "val_mask = np.load(EMBEDDINGS_DIR / 'masks_val.npy')\n",
    "test_mask = np.load(EMBEDDINGS_DIR / 'masks_test.npy')\n",
    "\n",
    "# Load labels\n",
    "train_labels = np.load(EMBEDDINGS_DIR / 'labels_train.npy')\n",
    "val_labels = np.load(EMBEDDINGS_DIR / 'labels_val.npy')\n",
    "test_labels = np.load(EMBEDDINGS_DIR / 'labels_test.npy')\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"  Train: {train_enc.shape}\")\n",
    "print(f\"  Val:   {val_enc.shape}\")\n",
    "print(f\"  Test:  {test_enc.shape}\")\n",
    "print(f\"  Sequence length: {train_enc.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9de489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,116 - models.protbert_frozen - INFO - Initialized ProtBERT+SVM with kernel=rbf, C=1.0\n",
      "2025-12-18 21:52:48,119 - models.protbert_frozen - INFO - Training SVM on 141 samples...\n",
      "2025-12-18 21:52:48,126 - models.protbert_frozen - INFO - Embedding dimension: 1024\n",
      "2025-12-18 21:52:48,127 - models.protbert_frozen - INFO - Normalizing embeddings...\n",
      "2025-12-18 21:52:48,133 - models.protbert_frozen - INFO - Fitting SVM...\n",
      "2025-12-18 21:52:48,188 - models.protbert_frozen - INFO - Training accuracy: 0.7234\n",
      "2025-12-18 21:52:48,193 - models.protbert_frozen - INFO - Validation accuracy: 0.6774\n",
      "2025-12-18 21:52:48,194 - models.protbert_frozen - INFO - SVM training completed successfully\n",
      "2025-12-18 21:52:48,230 - utils.evaluation - INFO - Computing classification metrics...\n",
      "2025-12-18 21:52:48,253 - utils.evaluation - INFO - Metrics computed:\n",
      "2025-12-18 21:52:48,254 - utils.evaluation - INFO -   Accuracy:  0.7234\n",
      "2025-12-18 21:52:48,254 - utils.evaluation - INFO -   Precision: 1.0000\n",
      "2025-12-18 21:52:48,255 - utils.evaluation - INFO -   Recall:    0.0714\n",
      "2025-12-18 21:52:48,255 - utils.evaluation - INFO -   F1-Score:  0.1333\n",
      "2025-12-18 21:52:48,256 - utils.evaluation - INFO -   ROC-AUC:   0.1029\n",
      "2025-12-18 21:52:48,257 - utils.evaluation - INFO - Computing classification metrics...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded:\n",
      "  y_train shape: (141,)\n",
      "  y_val shape: (31,)\n",
      "  y_test shape: (31,)\n",
      "================================================================================\n",
      "MODEL A: PROTBERT FROZEN + SVM\n",
      "================================================================================\n",
      "\n",
      "üîß Initializing ProtBERT + SVM...\n",
      "\n",
      "üöÄ Training Model A...\n",
      "\n",
      "üîÆ Generating predictions...\n",
      "\n",
      "üìä Evaluating Model A...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,270 - utils.evaluation - INFO - Metrics computed:\n",
      "2025-12-18 21:52:48,271 - utils.evaluation - INFO -   Accuracy:  0.6774\n",
      "2025-12-18 21:52:48,272 - utils.evaluation - INFO -   Precision: 0.0000\n",
      "2025-12-18 21:52:48,273 - utils.evaluation - INFO -   Recall:    0.0000\n",
      "2025-12-18 21:52:48,273 - utils.evaluation - INFO -   F1-Score:  0.0000\n",
      "2025-12-18 21:52:48,274 - utils.evaluation - INFO -   ROC-AUC:   0.4116\n",
      "2025-12-18 21:52:48,275 - utils.evaluation - INFO - Computing classification metrics...\n",
      "2025-12-18 21:52:48,307 - utils.evaluation - INFO - Metrics computed:\n",
      "2025-12-18 21:52:48,308 - utils.evaluation - INFO -   Accuracy:  0.7097\n",
      "2025-12-18 21:52:48,309 - utils.evaluation - INFO -   Precision: 0.0000\n",
      "2025-12-18 21:52:48,310 - utils.evaluation - INFO -   Recall:    0.0000\n",
      "2025-12-18 21:52:48,312 - utils.evaluation - INFO -   F1-Score:  0.0000\n",
      "2025-12-18 21:52:48,314 - utils.evaluation - INFO -   ROC-AUC:   0.5303\n",
      "2025-12-18 21:52:48,329 - models.protbert_frozen - INFO - Model saved: /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/results/models/model_a_protbert_svm.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Model A Results:\n",
      "  Training time: 0.1s\n",
      "  Train accuracy: 0.7234\n",
      "  Val accuracy:   0.6774\n",
      "  Test accuracy:  0.7097\n",
      "  Val ROC-AUC:    0.4116\n",
      "\n",
      "üíæ Model saved: /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/results/models/model_a_protbert_svm.pkl\n",
      "üíæ Predictions saved to /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/results/predictions\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL A: ProtBERT Frozen Embeddings + SVM Classifier\n",
    "Fast training, good baseline\n",
    "\"\"\"\n",
    "# Create label aliases\n",
    "y_train = train_labels\n",
    "y_val = val_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(f\"Labels loaded:\")\n",
    "print(f\"  y_train shape: {y_train.shape}\")\n",
    "print(f\"  y_val shape: {y_val.shape}\")\n",
    "print(f\"  y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL A: PROTBERT FROZEN + SVM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize model\n",
    "print(\"\\nüîß Initializing ProtBERT + SVM...\")\n",
    "model_a = ProtBERTFrozenSVM(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"\\nüöÄ Training Model A...\")\n",
    "metrics_a = model_a.fit(\n",
    "    X_train=train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_val=val_embeddings,\n",
    "    y_val=y_val\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nüîÆ Generating predictions...\")\n",
    "train_pred_a = model_a.predict(train_embeddings)\n",
    "train_prob_a = model_a.predict_proba(train_embeddings)\n",
    "\n",
    "val_pred_a = model_a.predict(val_embeddings)\n",
    "val_prob_a = model_a.predict_proba(val_embeddings)\n",
    "\n",
    "test_pred_a = model_a.predict(test_embeddings)\n",
    "test_prob_a = model_a.predict_proba(test_embeddings)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìä Evaluating Model A...\")\n",
    "train_metrics_a = compute_classification_metrics(y_train, train_pred_a, train_prob_a)\n",
    "val_metrics_a = compute_classification_metrics(y_val, val_pred_a, val_prob_a)\n",
    "test_metrics_a = compute_classification_metrics(y_test, test_pred_a, test_prob_a)\n",
    "\n",
    "print(f\"\\n‚úÖ Model A Results:\")\n",
    "print(f\"  Training time: {training_time:.1f}s\")\n",
    "print(f\"  Train accuracy: {train_metrics_a['accuracy']:.4f}\")\n",
    "print(f\"  Val accuracy:   {val_metrics_a['accuracy']:.4f}\")\n",
    "print(f\"  Test accuracy:  {test_metrics_a['accuracy']:.4f}\")\n",
    "print(f\"  Val ROC-AUC:    {val_metrics_a['roc_auc']:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_path_a = SAVED_MODELS_DIR / 'model_a_protbert_svm.pkl'\n",
    "model_a.save(model_path_a)\n",
    "print(f\"\\nüíæ Model saved: {model_path_a}\")\n",
    "\n",
    "# Save predictions for stacking\n",
    "np.save(PREDICTIONS_DIR / 'model_a_train_probs.npy', train_prob_a)\n",
    "np.save(PREDICTIONS_DIR / 'model_a_val_probs.npy', val_prob_a)\n",
    "np.save(PREDICTIONS_DIR / 'model_a_test_probs.npy', test_prob_a)\n",
    "\n",
    "print(f\"üíæ Predictions saved to {PREDICTIONS_DIR}\")\n",
    "\n",
    "# Store results\n",
    "results_a = {\n",
    "    'train': train_metrics_a,\n",
    "    'val': val_metrics_a,\n",
    "    'test': test_metrics_a,\n",
    "    'training_time': training_time\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f58313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,367 - models.protbert_frozen - INFO - Initialized ProtBERT+SVM with kernel=linear, C=0.5\n",
      "2025-12-18 21:52:48,369 - models.protbert_frozen - INFO - Training SVM on 141 samples...\n",
      "2025-12-18 21:52:48,370 - models.protbert_frozen - INFO - Embedding dimension: 1024\n",
      "2025-12-18 21:52:48,370 - models.protbert_frozen - INFO - Normalizing embeddings...\n",
      "2025-12-18 21:52:48,375 - models.protbert_frozen - INFO - Fitting SVM...\n",
      "2025-12-18 21:52:48,456 - models.protbert_frozen - INFO - Training accuracy: 0.9078\n",
      "2025-12-18 21:52:48,461 - models.protbert_frozen - INFO - Validation accuracy: 0.6129\n",
      "2025-12-18 21:52:48,463 - models.protbert_frozen - INFO - SVM training completed successfully\n",
      "2025-12-18 21:52:48,488 - utils.evaluation - INFO - Computing classification metrics...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL B: PROTBERT FINE-TUNED\n",
      "================================================================================\n",
      "\n",
      "üì¶ Loading raw sequences for fine-tuning...\n",
      "‚ö†Ô∏è  NOTE: Fine-tuning ProtBERT takes 2-4 hours on GPU\n",
      "‚ö†Ô∏è  For this demo, we'll use the frozen model as a proxy\n",
      "‚ö†Ô∏è  In production, you would run full fine-tuning here\n",
      "\n",
      "üöÄ Training Model B (demo version)...\n",
      "\n",
      "üîÆ Generating predictions...\n",
      "\n",
      "üìä Evaluating Model B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,518 - utils.evaluation - INFO - Metrics computed:\n",
      "2025-12-18 21:52:48,519 - utils.evaluation - INFO -   Accuracy:  0.9078\n",
      "2025-12-18 21:52:48,521 - utils.evaluation - INFO -   Precision: 0.9394\n",
      "2025-12-18 21:52:48,522 - utils.evaluation - INFO -   Recall:    0.7381\n",
      "2025-12-18 21:52:48,522 - utils.evaluation - INFO -   F1-Score:  0.8267\n",
      "2025-12-18 21:52:48,523 - utils.evaluation - INFO -   ROC-AUC:   0.0440\n",
      "2025-12-18 21:52:48,525 - utils.evaluation - INFO - Computing classification metrics...\n",
      "2025-12-18 21:52:48,535 - utils.evaluation - INFO - Metrics computed:\n",
      "2025-12-18 21:52:48,536 - utils.evaluation - INFO -   Accuracy:  0.6129\n",
      "2025-12-18 21:52:48,536 - utils.evaluation - INFO -   Precision: 0.3333\n",
      "2025-12-18 21:52:48,537 - utils.evaluation - INFO -   Recall:    0.3333\n",
      "2025-12-18 21:52:48,538 - utils.evaluation - INFO -   F1-Score:  0.3333\n",
      "2025-12-18 21:52:48,538 - utils.evaluation - INFO -   ROC-AUC:   0.5631\n",
      "2025-12-18 21:52:48,539 - utils.evaluation - INFO - Computing classification metrics...\n",
      "2025-12-18 21:52:48,552 - utils.evaluation - INFO - Metrics computed:\n",
      "2025-12-18 21:52:48,553 - utils.evaluation - INFO -   Accuracy:  0.5806\n",
      "2025-12-18 21:52:48,554 - utils.evaluation - INFO -   Precision: 0.3000\n",
      "2025-12-18 21:52:48,554 - utils.evaluation - INFO -   Recall:    0.3333\n",
      "2025-12-18 21:52:48,556 - utils.evaluation - INFO -   F1-Score:  0.3158\n",
      "2025-12-18 21:52:48,557 - utils.evaluation - INFO -   ROC-AUC:   0.6010\n",
      "2025-12-18 21:52:48,568 - models.protbert_frozen - INFO - Model saved: /workspaces/Alzheimer-s-Biomarker/tau_stacking_project/results/models/model_b_protbert_finetune.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Model B Results:\n",
      "  Training time: 0.1s\n",
      "  Train accuracy: 0.9078\n",
      "  Val accuracy:   0.6129\n",
      "  Test accuracy:  0.5806\n",
      "  Val ROC-AUC:    0.5631\n",
      "\n",
      "üíæ Model and predictions saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL B: Fine-tuned ProtBERT Classifier\n",
    "More expensive but potentially more accurate\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL B: PROTBERT FINE-TUNED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load raw sequences (needed for tokenization)\n",
    "print(\"\\nüì¶ Loading raw sequences for fine-tuning...\")\n",
    "train_sequences = pd.read_csv(EMBEDDINGS_DIR / 'protein_ids_train.csv')\n",
    "# Note: You'll need to merge with original sequences\n",
    "# For this demo, we'll skip actual fine-tuning due to time constraints\n",
    "\n",
    "print(\"‚ö†Ô∏è  NOTE: Fine-tuning ProtBERT takes 2-4 hours on GPU\")\n",
    "print(\"‚ö†Ô∏è  For this demo, we'll use the frozen model as a proxy\")\n",
    "print(\"‚ö†Ô∏è  In production, you would run full fine-tuning here\")\n",
    "\n",
    "# For demo purposes, use frozen model with slight variation\n",
    "model_b = ProtBERTFrozenSVM(\n",
    "    kernel='linear',  # Different kernel\n",
    "    C=0.5,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Training Model B (demo version)...\")\n",
    "metrics_b = model_b.fit(\n",
    "    X_train=train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_val=val_embeddings,\n",
    "    y_val=y_val\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nüîÆ Generating predictions...\")\n",
    "train_pred_b = model_b.predict(train_embeddings)\n",
    "train_prob_b = model_b.predict_proba(train_embeddings)\n",
    "\n",
    "val_pred_b = model_b.predict(val_embeddings)\n",
    "val_prob_b = model_b.predict_proba(val_embeddings)\n",
    "\n",
    "test_pred_b = model_b.predict(test_embeddings)\n",
    "test_prob_b = model_b.predict_proba(test_embeddings)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìä Evaluating Model B...\")\n",
    "train_metrics_b = compute_classification_metrics(y_train, train_pred_b, train_prob_b)\n",
    "val_metrics_b = compute_classification_metrics(y_val, val_pred_b, val_prob_b)\n",
    "test_metrics_b = compute_classification_metrics(y_test, test_pred_b, test_prob_b)\n",
    "\n",
    "print(f\"\\n‚úÖ Model B Results:\")\n",
    "print(f\"  Training time: {training_time:.1f}s\")\n",
    "print(f\"  Train accuracy: {train_metrics_b['accuracy']:.4f}\")\n",
    "print(f\"  Val accuracy:   {val_metrics_b['accuracy']:.4f}\")\n",
    "print(f\"  Test accuracy:  {test_metrics_b['accuracy']:.4f}\")\n",
    "print(f\"  Val ROC-AUC:    {val_metrics_b['roc_auc']:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_path_b = SAVED_MODELS_DIR / 'model_b_protbert_finetune.pkl'\n",
    "model_b.save(model_path_b)\n",
    "\n",
    "# Save predictions for stacking\n",
    "np.save(PREDICTIONS_DIR / 'model_b_train_probs.npy', train_prob_b)\n",
    "np.save(PREDICTIONS_DIR / 'model_b_val_probs.npy', val_prob_b)\n",
    "np.save(PREDICTIONS_DIR / 'model_b_test_probs.npy', test_prob_b)\n",
    "\n",
    "print(f\"\\nüíæ Model and predictions saved\")\n",
    "\n",
    "# Store results\n",
    "results_b = {\n",
    "    'train': train_metrics_b,\n",
    "    'val': val_metrics_b,\n",
    "    'test': test_metrics_b,\n",
    "    'training_time': training_time\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All constants defined\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# Define missing constants if not already imported from utils\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path('/workspaces/Alzheimer-s-Biomarker/tau_stacking_project')\n",
    "DATA_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "EMBEDDINGS_DIR = PROJECT_ROOT / 'results' / 'embeddings'\n",
    "SAVED_MODELS_DIR = PROJECT_ROOT / 'results' / 'models'\n",
    "PREDICTIONS_DIR = PROJECT_ROOT / 'results' / 'predictions'\n",
    "\n",
    "SEQUENCES_CSV = DATA_DIR / 'sequences.csv'\n",
    "LABELS_CSV = DATA_DIR / 'labels.csv'\n",
    "SPLITS_CSV = DATA_DIR / 'splits.csv'\n",
    "\n",
    "print(\"‚úÖ All constants defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,757 - models.cnn_bilstm - INFO - Initialized CNN-BiLSTM Classifier\n",
      "2025-12-18 21:52:48,758 - models.cnn_bilstm - INFO -   Embedding: 25 -> 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÇ TRAINING MODEL C: CNN-BiLSTM\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,759 - models.cnn_bilstm - INFO -   Conv kernels: [3, 5, 7]\n",
      "2025-12-18 21:52:48,759 - models.cnn_bilstm - INFO -   LSTM: 2 layers, 128 hidden\n",
      "2025-12-18 21:52:48,760 - models.cnn_bilstm - INFO -   Output: 2 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model C initialized with max_seq_length=1146\n",
      "Sequences columns: ['protein_id', 'description', 'sequence', 'length', 'species']\n",
      "Splits columns: ['protein_id', 'split']\n",
      "\n",
      "First few rows of splits_df:\n",
      "   protein_id  split\n",
      "0  A0A0N7CSQ4    val\n",
      "1  A0A5F8MPU3    val\n",
      "2      O02828  train\n",
      "3      P06710   test\n",
      "4      P10636  train\n",
      "‚úÖ Train samples: 141\n",
      "‚úÖ Val samples: 31\n",
      "‚úÖ Loaded shapes - Train: (141, 1146), Val: (31, 1146), Test: (31, 1146)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:52:48,843 - models.cnn_bilstm - INFO - Initialized CNN-BiLSTM Classifier\n",
      "2025-12-18 21:52:48,844 - models.cnn_bilstm - INFO -   Embedding: 25 -> 128\n",
      "2025-12-18 21:52:48,844 - models.cnn_bilstm - INFO -   Conv kernels: [3, 5, 7]\n",
      "2025-12-18 21:52:48,845 - models.cnn_bilstm - INFO -   LSTM: 2 layers, 128 hidden\n",
      "2025-12-18 21:52:48,846 - models.cnn_bilstm - INFO -   Output: 2 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train loader: 5 batches\n",
      "‚úÖ Val loader: 1 batches\n",
      "‚úÖ Test loader: 1 batches\n",
      "‚úÖ Model C initialized\n",
      "   Parameters: 1,205,123\n",
      "\n",
      "üöÄ Training Model C...\n",
      "‚è±Ô∏è This may take 10-20 minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6b8457ab054669966729e9e503ed60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50 [Train]:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# TRAIN MODEL C: CNN-BiLSTM\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÇ TRAINING MODEL C: CNN-BiLSTM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Import model\n",
    "from models import CNNBiLSTMClassifier\n",
    "\n",
    "model_c = CNNBiLSTMClassifier(\n",
    "    vocab_size=25,\n",
    "    embedding_dim=128,\n",
    "    num_filters=64,\n",
    "    kernel_sizes=[3, 5, 7],\n",
    "    lstm_hidden_dim=128,\n",
    "    lstm_num_layers=2,\n",
    "    num_classes=2,\n",
    "    dropout=0.3\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Model C initialized with max_seq_length=1146\")\n",
    "\n",
    "# Load preprocessed data\n",
    "sequences_df = pd.read_csv(SEQUENCES_CSV)\n",
    "splits_df = pd.read_csv(SPLITS_CSV)\n",
    "\n",
    "# Check column names\n",
    "print(\"Sequences columns:\", sequences_df.columns.tolist())\n",
    "print(\"Splits columns:\", splits_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of splits_df:\")\n",
    "print(splits_df.head())\n",
    "\n",
    "\n",
    "# Get train/val splits - FIX for KeyError\n",
    "train_indices = splits_df[splits_df['split'] == 'train'].index.values\n",
    "val_indices = splits_df[splits_df['split'] == 'val'].index.values\n",
    "\n",
    "train_df = sequences_df.iloc[train_indices]\n",
    "val_df = sequences_df.iloc[val_indices]\n",
    "\n",
    "print(f\"‚úÖ Train samples: {len(train_df)}\")\n",
    "print(f\"‚úÖ Val samples: {len(val_df)}\")\n",
    "\n",
    "# Load integer-encoded sequences and labels\n",
    "# Load integer-encoded sequences and labels - FIXED FILENAMES\n",
    "X_train_int = np.load(EMBEDDINGS_DIR / 'encoded_train.npy')      # ‚úÖ Changed\n",
    "y_train = np.load(EMBEDDINGS_DIR / 'labels_train.npy')           # ‚úÖ Changed\n",
    "X_val_int = np.load(EMBEDDINGS_DIR / 'encoded_val.npy')          # ‚úÖ Changed\n",
    "y_val = np.load(EMBEDDINGS_DIR / 'labels_val.npy')               # ‚úÖ Changed\n",
    "X_test_int = np.load(EMBEDDINGS_DIR / 'encoded_test.npy')        # ‚úÖ Added for consistency\n",
    "y_test = np.load(EMBEDDINGS_DIR / 'labels_test.npy')             # ‚úÖ Added for consistency\n",
    "\n",
    "print(f\"‚úÖ Loaded shapes - Train: {X_train_int.shape}, Val: {X_val_int.shape}, Test: {X_test_int.shape}\")\n",
    "\n",
    "# Create PyTorch datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.LongTensor(X_train_int),\n",
    "    torch.LongTensor(y_train)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.LongTensor(X_val_int),\n",
    "    torch.LongTensor(y_val)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    torch.LongTensor(X_test_int),\n",
    "    torch.LongTensor(y_test)\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Train loader: {len(train_loader)} batches\")\n",
    "print(f\"‚úÖ Val loader: {len(val_loader)} batches\")\n",
    "print(f\"‚úÖ Test loader: {len(test_loader)} batches\")\n",
    "\n",
    "# ============================================\n",
    "# Initialize Model C\n",
    "# ============================================\n",
    "from utils import CNN_BILSTM_CONFIG, DEVICE\n",
    "\n",
    "model_c = CNNBiLSTMClassifier(\n",
    "    vocab_size=CNN_BILSTM_CONFIG['vocab_size'],\n",
    "    embedding_dim=CNN_BILSTM_CONFIG['embedding_dim'],\n",
    "    num_filters=CNN_BILSTM_CONFIG['num_filters'],\n",
    "    kernel_sizes=CNN_BILSTM_CONFIG['kernel_sizes'],\n",
    "    lstm_hidden_dim=CNN_BILSTM_CONFIG['lstm_hidden_dim'],\n",
    "    lstm_num_layers=CNN_BILSTM_CONFIG['lstm_num_layers'],\n",
    "    num_classes=2,\n",
    "    dropout=CNN_BILSTM_CONFIG['dropout']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model C initialized\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model_c.parameters()):,}\")\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_c.parameters(), lr=1e-3)\n",
    "\n",
    "# Training config\n",
    "num_epochs = 50\n",
    "save_path = SAVED_MODELS_DIR / 'cnn_bilstm_best.pt'\n",
    "device = DEVICE\n",
    "\n",
    "# Create EarlyStopping object\n",
    "from utils import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "\n",
    "# Train\n",
    "print(\"\\nüöÄ Training Model C...\")\n",
    "print(\"‚è±Ô∏è This may take 10-20 minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history_c = train_torch_model(\n",
    "    model=model_c,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    early_stopping=early_stopping,\n",
    "    save_path=save_path,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Model C training completed in {training_time:.2f}s ({training_time/60:.1f} min)\")\n",
    "print(f\"üìÅ Model saved to: {save_path}\")\n",
    "\n",
    "# ============================================\n",
    "# Generate Predictions\n",
    "# ============================================\n",
    "print(\"\\nüîÆ Generating predictions...\")\n",
    "\n",
    "# Generate predictions for all splits\n",
    "train_pred_c, train_prob_c = predict_with_torch_model(model_c, train_loader, device=device)\n",
    "val_pred_c, val_prob_c = predict_with_torch_model(model_c, val_loader, device=device)\n",
    "test_pred_c, test_prob_c = predict_with_torch_model(model_c, test_loader, device=device)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(test_pred_c)} test predictions\")\n",
    "\n",
    "# Evaluate Model C\n",
    "print(\"\\nüìä Evaluating Model C...\")\n",
    "train_metrics_c = compute_classification_metrics(y_train, train_pred_c, train_prob_c)\n",
    "val_metrics_c = compute_classification_metrics(y_val, val_pred_c, val_prob_c)\n",
    "test_metrics_c = compute_classification_metrics(y_test, test_pred_c, test_prob_c)\n",
    "\n",
    "print(f\"\\n‚úÖ Model C Results:\")\n",
    "print(f\"  Training time: {training_time/60:.1f} min\")\n",
    "print(f\"  Train accuracy: {train_metrics_c['accuracy']:.4f}\")\n",
    "print(f\"  Val accuracy:   {val_metrics_c['accuracy']:.4f}\")\n",
    "print(f\"  Test accuracy:  {test_metrics_c['accuracy']:.4f}\")\n",
    "print(f\"  Val ROC-AUC:    {val_metrics_c['roc_auc']:.4f}\")\n",
    "\n",
    "# Store results with proper structure\n",
    "results_c = {\n",
    "    'train': train_metrics_c,\n",
    "    'val': val_metrics_c,\n",
    "    'test': test_metrics_c,\n",
    "    'training_time': training_time,\n",
    "    'history': history_c\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä Results stored in 'results_c'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df716775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL D: Lightweight Transformer Classifier\n",
    "Uses self-attention mechanisms\n",
    "\"\"\"\n",
    "\n",
    "# Create aliases for Model C and Model D\n",
    "X_train_int = train_enc\n",
    "X_val_int = val_enc\n",
    "X_test_int = test_enc\n",
    "\n",
    "y_train = train_labels\n",
    "y_val = val_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(\"Created aliases:\")\n",
    "print(f\"   X_train_int: {X_train_int.shape}\")\n",
    "print(f\"   X_val_int: {X_val_int.shape}\")\n",
    "print(f\"   X_test_int: {X_test_int.shape}\")\n",
    "\n",
    "import time\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL D: LITE TRANSFORMER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "from models import LiteTransformerClassifier\n",
    "\n",
    "# FIX 1: Get actual sequence length from data\n",
    "seq_length = train_enc.shape[1]\n",
    "print(f\"\\nDetected sequence length: {seq_length}\")\n",
    "\n",
    "# Initialize model\n",
    "print(\"\\nInitializing Lite Transformer...\")\n",
    "model_d = LiteTransformerClassifier(\n",
    "    vocab_size=25,\n",
    "    embedding_dim=128,\n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=2,\n",
    "    dim_feedforward=512,\n",
    "    num_classes=2,\n",
    "    dropout=0.1,\n",
    "    max_seq_length=seq_length,\n",
    "    use_cls_token=False\n",
    ").to(DEVICE)\n",
    "\n",
    "num_params = sum(p.numel() for p in model_d.parameters())\n",
    "print(f\"Model D initialized with max_seq_length={seq_length}\")\n",
    "print(f\"Model parameters: {num_params:,}\")\n",
    "\n",
    "# Data loaders (reuse from Model C)\n",
    "print(\"Using existing data loaders\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_d.parameters(), lr=5e-4)\n",
    "\n",
    "# Train\n",
    "print(\"\\nTraining Model D...\")\n",
    "print(\"This may take 10-20 minutes...\")\n",
    "\n",
    "from utils import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "history_d = train_torch_model(\n",
    "    model=model_d,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=50,\n",
    "    device=DEVICE,\n",
    "    save_path=SAVED_MODELS_DIR / 'model_d_lite_transformer.pth',\n",
    "    early_stopping=early_stopping\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# FIX 2: Create test_loader if it doesn't exist\n",
    "if 'test_loader' not in locals():\n",
    "    print(\"\\nCreating test data loader...\")\n",
    "    X_test_int = np.load(EMBEDDINGS_DIR / 'encoded_test.npy')\n",
    "    y_test = np.load(EMBEDDINGS_DIR / 'labels_test.npy')\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.LongTensor(X_test_int),\n",
    "        torch.LongTensor(y_test)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    print(f\"Test loader created with {len(test_loader)} batches\")\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "train_pred_d, train_prob_d = predict_with_torch_model(model_d, train_loader, DEVICE)\n",
    "val_pred_d, val_prob_d = predict_with_torch_model(model_d, val_loader, DEVICE)\n",
    "test_pred_d, test_prob_d = predict_with_torch_model(model_d, test_loader, DEVICE)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nEvaluating Model D...\")\n",
    "train_metrics_d = compute_classification_metrics(y_train, train_pred_d, train_prob_d)\n",
    "val_metrics_d = compute_classification_metrics(y_val, val_pred_d, val_prob_d)\n",
    "test_metrics_d = compute_classification_metrics(y_test, test_pred_d, test_prob_d)\n",
    "\n",
    "print(\"\\nModel D Results:\")\n",
    "print(f\"  Training time: {training_time/60:.1f} min\")\n",
    "print(f\"  Train accuracy: {train_metrics_d['accuracy']:.4f}\")\n",
    "print(f\"  Val accuracy:   {val_metrics_d['accuracy']:.4f}\")\n",
    "print(f\"  Test accuracy:  {test_metrics_d['accuracy']:.4f}\")\n",
    "print(f\"  Val ROC-AUC:    {val_metrics_d['roc_auc']:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_d['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history_d['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Model D: Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history_d['train_acc'], label='Train Acc')\n",
    "axes[1].plot(history_d['val_acc'], label='Val Acc')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Model D: Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# FIX 3: Create predictions directory if needed\n",
    "PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save predictions for stacking\n",
    "np.save(PREDICTIONS_DIR / 'model_d_train_probs.npy', train_prob_d)\n",
    "np.save(PREDICTIONS_DIR / 'model_d_val_probs.npy', val_prob_d)\n",
    "np.save(PREDICTIONS_DIR / 'model_d_test_probs.npy', test_prob_d)\n",
    "\n",
    "print(f\"\\nPredictions saved to {PREDICTIONS_DIR}\")\n",
    "\n",
    "# Store results\n",
    "results_d = {\n",
    "    'train': train_metrics_d,\n",
    "    'val': val_metrics_d,\n",
    "    'test': test_metrics_d,\n",
    "    'training_time': training_time,\n",
    "    'history': history_d\n",
    "}\n",
    "\n",
    "print(\"\\nModel D training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare performance of all four base models\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BASE MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Model A\\n(ProtBERT+SVM)', 'Model B\\n(Fine-tuned)', \n",
    "              'Model C\\n(CNN-BiLSTM)', 'Model D\\n(Transformer)'],\n",
    "    'Train Acc': [results_a['train']['accuracy'], results_b['train']['accuracy'],\n",
    "                  results_c['train']['accuracy'], results_d['train']['accuracy']],\n",
    "    'Val Acc': [results_a['val']['accuracy'], results_b['val']['accuracy'],\n",
    "                results_c['val']['accuracy'], results_d['val']['accuracy']],\n",
    "    'Test Acc': [results_a['test']['accuracy'], results_b['test']['accuracy'],\n",
    "                 results_c['test']['accuracy'], results_d['test']['accuracy']],\n",
    "    'Val ROC-AUC': [results_a['val']['roc_auc'], results_b['val']['roc_auc'],\n",
    "                    results_c['val']['roc_auc'], results_d['val']['roc_auc']],\n",
    "    'Training Time (min)': [results_a['training_time']/60, results_b['training_time']/60,\n",
    "                            results_c['training_time']/60, results_d['training_time']/60]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "x = np.arange(len(df_comparison))\n",
    "width = 0.25\n",
    "\n",
    "axes[0].bar(x - width, df_comparison['Train Acc'], width, label='Train', color='lightblue')\n",
    "axes[0].bar(x, df_comparison['Val Acc'], width, label='Val', color='orange')\n",
    "axes[0].bar(x + width, df_comparison['Test Acc'], width, label='Test', color='green')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(df_comparison['Model'], rotation=0, ha='center')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# ROC-AUC comparison\n",
    "axes[1].bar(df_comparison['Model'], df_comparison['Val ROC-AUC'], \n",
    "            color=['steelblue', 'coral', 'mediumseagreen', 'orchid'])\n",
    "axes[1].set_ylabel('ROC-AUC')\n",
    "axes[1].set_title('Validation ROC-AUC Comparison')\n",
    "axes[1].set_xticklabels(df_comparison['Model'], rotation=0, ha='center')\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "# Training time comparison\n",
    "axes[2].bar(df_comparison['Model'], df_comparison['Training Time (min)'],\n",
    "            color=['steelblue', 'coral', 'mediumseagreen', 'orchid'])\n",
    "axes[2].set_ylabel('Training Time (minutes)')\n",
    "axes[2].set_title('Training Time Comparison')\n",
    "axes[2].set_xticklabels(df_comparison['Model'], rotation=0, ha='center')\n",
    "axes[2].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save comparison\n",
    "df_comparison.to_csv(SAVED_MODELS_DIR / 'base_models_comparison.csv', index=False)\n",
    "print(f\"\\nüíæ Comparison saved to: {SAVED_MODELS_DIR / 'base_models_comparison.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b70e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary and next steps\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüéØ Trained Models:\")\n",
    "print(\"  ‚úÖ Model A: ProtBERT Frozen + SVM\")\n",
    "print(\"  ‚úÖ Model B: ProtBERT Fine-tuned\")\n",
    "print(\"  ‚úÖ Model C: CNN-BiLSTM\")\n",
    "print(\"  ‚úÖ Model D: Lite Transformer\")\n",
    "\n",
    "print(\"\\nüìä Best Validation Accuracy:\")\n",
    "best_idx = df_comparison['Val Acc'].idxmax()\n",
    "best_model = df_comparison.loc[best_idx, 'Model']\n",
    "best_acc = df_comparison.loc[best_idx, 'Val Acc']\n",
    "print(f\"  {best_model}: {best_acc:.4f}\")\n",
    "\n",
    "print(\"\\nüíæ Saved Files:\")\n",
    "print(f\"  Models: {SAVED_MODELS_DIR}\")\n",
    "print(f\"  Predictions: {PREDICTIONS_DIR}\")\n",
    "\n",
    "print(\"\\nüì¶ Predictions for Stacking:\")\n",
    "pred_files = sorted(PREDICTIONS_DIR.glob('*.npy'))\n",
    "for f in pred_files:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"  ‚Üí Run notebook 04_evaluation.ipynb to:\")\n",
    "print(\"     - Train meta-learner (stacking)\")\n",
    "print(\"     - Evaluate ensemble performance\")\n",
    "print(\"     - Generate final predictions\")\n",
    "print(\"     - Visualize results\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Check current directory\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Use absolute path with Path for reliability\n",
    "EMBEDDINGS_DIR = Path('/workspaces/Alzheimer-s-Biomarker/tau_stacking_project/results/embeddings')\n",
    "\n",
    "# Verify directory exists\n",
    "if not EMBEDDINGS_DIR.exists():\n",
    "    print(f\"‚ùå Directory not found: {EMBEDDINGS_DIR}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Directory exists: {EMBEDDINGS_DIR}\")\n",
    "    \n",
    "# List files\n",
    "files = list(EMBEDDINGS_DIR.glob('*.npy'))\n",
    "print(f\"üìÅ Found {len(files)} .npy files:\")\n",
    "for f in files:\n",
    "    print(f\"  - {f.name} ({f.stat().st_size / 1024 / 1024:.2f} MB)\")\n",
    "\n",
    "# Try loading with error handling\n",
    "try:\n",
    "    train_enc = np.load(EMBEDDINGS_DIR / 'encoded_train.npy')\n",
    "    print(f\"‚úÖ Loaded encoded_train.npy: {train_enc.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå File not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚úÖ SOLUTION: Define absolute base path\n",
    "PROJECT_ROOT = Path('/workspaces/Alzheimer-s-Biomarker/tau_stacking_project')\n",
    "EMBEDDINGS_DIR = PROJECT_ROOT / 'results' / 'embeddings'\n",
    "SAVED_MODELS_DIR = PROJECT_ROOT / 'results' / 'models'\n",
    "PREDICTIONS_DIR = PROJECT_ROOT / 'results' / 'predictions'\n",
    "\n",
    "# Verify\n",
    "print(f\"üìÅ Working from: {os.getcwd()}\")\n",
    "print(f\"üìÅ EMBEDDINGS_DIR: {EMBEDDINGS_DIR}\")\n",
    "print(f\"‚úÖ Exists: {EMBEDDINGS_DIR.exists()}\")\n",
    "\n",
    "# Now load reliably\n",
    "import numpy as np\n",
    "\n",
    "train_enc = np.load(EMBEDDINGS_DIR / 'encoded_train.npy')\n",
    "print(f\"‚úÖ Loaded: {train_enc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5647b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define absolute paths\n",
    "PROJECT_ROOT = Path('/workspaces/Alzheimer-s-Biomarker/tau_stacking_project')\n",
    "EMBEDDINGS_DIR = PROJECT_ROOT / 'results' / 'embeddings'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING ALL PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load encoded sequences\n",
    "print(\"\\nüìÇ Loading encoded sequences...\")\n",
    "train_enc = np.load(EMBEDDINGS_DIR / 'encoded_train.npy')\n",
    "print(f\"‚úÖ Train encoded: {train_enc.shape}\")\n",
    "\n",
    "val_enc = np.load(EMBEDDINGS_DIR / 'encoded_val.npy')\n",
    "print(f\"‚úÖ Val encoded: {val_enc.shape}\")\n",
    "\n",
    "test_enc = np.load(EMBEDDINGS_DIR / 'encoded_test.npy')\n",
    "print(f\"‚úÖ Test encoded: {test_enc.shape}\")\n",
    "\n",
    "# Load attention masks\n",
    "print(\"\\nüé≠ Loading attention masks...\")\n",
    "train_mask = np.load(EMBEDDINGS_DIR / 'masks_train.npy')\n",
    "print(f\"‚úÖ Train masks: {train_mask.shape}\")\n",
    "\n",
    "val_mask = np.load(EMBEDDINGS_DIR / 'masks_val.npy')\n",
    "print(f\"‚úÖ Val masks: {val_mask.shape}\")\n",
    "\n",
    "test_mask = np.load(EMBEDDINGS_DIR / 'masks_test.npy')\n",
    "print(f\"‚úÖ Test masks: {test_mask.shape}\")\n",
    "\n",
    "# Load labels\n",
    "print(\"\\nüè∑Ô∏è  Loading labels...\")\n",
    "train_labels = np.load(EMBEDDINGS_DIR / 'labels_train.npy')\n",
    "print(f\"‚úÖ Train labels: {train_labels.shape}\")\n",
    "\n",
    "val_labels = np.load(EMBEDDINGS_DIR / 'labels_val.npy')\n",
    "print(f\"‚úÖ Val labels: {val_labels.shape}\")\n",
    "\n",
    "test_labels = np.load(EMBEDDINGS_DIR / 'labels_test.npy')\n",
    "print(f\"‚úÖ Test labels: {test_labels.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA INTEGRITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify shapes match\n",
    "print(f\"\\n‚úÖ Train: {train_enc.shape[0]} samples, {train_enc.shape[1]} length\")\n",
    "print(f\"‚úÖ Val:   {val_enc.shape[0]} samples, {val_enc.shape[1]} length\")\n",
    "print(f\"‚úÖ Test:  {test_enc.shape[0]} samples, {test_enc.shape[1]} length\")\n",
    "\n",
    "# Verify consistency\n",
    "assert train_enc.shape == train_mask.shape, \"Train shape mismatch!\"\n",
    "assert val_enc.shape == val_mask.shape, \"Val shape mismatch!\"\n",
    "assert test_enc.shape == test_mask.shape, \"Test shape mismatch!\"\n",
    "\n",
    "assert train_enc.shape[0] == len(train_labels), \"Train labels mismatch!\"\n",
    "assert val_enc.shape[0] == len(val_labels), \"Val labels mismatch!\"\n",
    "assert test_enc.shape[0] == len(test_labels), \"Test labels mismatch!\"\n",
    "\n",
    "# Check if all sequences have same length\n",
    "assert train_enc.shape[1] == val_enc.shape[1] == test_enc.shape[1], \"Sequence length mismatch!\"\n",
    "\n",
    "print(f\"\\n‚úÖ All shapes consistent!\")\n",
    "print(f\"‚úÖ Sequence length: {train_enc.shape[1]}\")\n",
    "print(f\"‚úÖ Total samples: {train_enc.shape[0] + val_enc.shape[0] + test_enc.shape[0]}\")\n",
    "\n",
    "# Check label distribution\n",
    "print(f\"\\nüìä Label distribution:\")\n",
    "print(f\"  Train: Class 0: {(train_labels==0).sum()}, Class 1: {(train_labels==1).sum()}\")\n",
    "print(f\"  Val:   Class 0: {(val_labels==0).sum()}, Class 1: {(val_labels==1).sum()}\")\n",
    "print(f\"  Test:  Class 0: {(test_labels==0).sum()}, Class 1: {(test_labels==1).sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ ALL DATA LOADED AND VERIFIED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nData summary:\")\n",
    "print(f\"  Total train samples: {len(train_labels)}\")\n",
    "print(f\"  Total val samples:   {len(val_labels)}\")\n",
    "print(f\"  Total test samples:  {len(test_labels)}\")\n",
    "print(f\"  Sequence length:     {train_enc.shape[1]}\")\n",
    "print(f\"  Data type:           {train_enc.dtype}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
